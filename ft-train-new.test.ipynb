{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewhealey/micromamba/envs/sam2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Anything custom imported\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import fine_tune.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = None\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in datasets/Climbing-6 to coco-segmentation:: 100%|██████████| 3193/3193 [00:00<00:00, 39190.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to datasets/Climbing-6 in coco-segmentation:: 100%|██████████| 51/51 [00:00<00:00, 1981.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# set DATASET_DIRECTORY env var to \"datasets/\"\n",
    "os.environ[\"DATASET_DIRECTORY\"] = \"datasets\"\n",
    "\n",
    "from fine_tune.configs.climbing import *\n",
    "\n",
    "assert cfg is not None,\"Must set config\"\n",
    "assert dataset is not None,\"Must set training dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "seed = 5\n",
    "torch.manual_seed(seed)\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting classes ['climbing-holds', 'floor', 'person']\n"
     ]
    }
   ],
   "source": [
    "from fine_tune.load_datasets import load_datasets\n",
    "\n",
    "train_dataset,valid_dataset = load_datasets(cfg.data,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "warm started\n"
     ]
    }
   ],
   "source": [
    "from fine_tune.models import WrappedSamModel\n",
    "\n",
    "sam = WrappedSamModel(cfg).to(device)\n",
    "\n",
    "encoder = sam.encoder\n",
    "decoder = sam.decoder\n",
    "predictor = sam.predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewhealey\u001b[0m (\u001b[33mroboflow2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "run_num = None\n",
    "\n",
    "if run_num is not None:\n",
    "    sam.load_state_dict(torch.load(f\"runs/{run_num}/trainable.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20, 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  8.89it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 4139.56it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 315590.83it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.88it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 4621.82it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 113743.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from fine_tune.load_datasets import prepare_torch_dataset\n",
    "\n",
    "print(cfg.data.points_per_mask)\n",
    "\n",
    "curr_dataset = prepare_torch_dataset(predictor,cfg,train_dataset,max_prompts=cfg.data.train_prompts)\n",
    "valid_curr_dataset = prepare_torch_dataset(predictor,cfg,valid_dataset,max_prompts=cfg.data.valid_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3809839576.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[42], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    box_prompts = [img_name,prompt for img_name,prompt in curr_dataset.prompts if prompt.box is not None]\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from fine_tune.viz import render_prompt\n",
    "from random import randrange\n",
    "import cv2\n",
    "\n",
    "print([prompt.box is not None for _,prompt in curr_dataset.prompts])\n",
    "\n",
    "box_prompts = [(img_name,prompt) for img_name,prompt in curr_dataset.prompts if prompt.box is not None]\n",
    "\n",
    "rand_img_name,rand_prompt = box_prompts[0]\n",
    "rand_img = train_dataset.images[rand_img_name]\n",
    "\n",
    "# save rand_img and rand_prompt to seqs/demo.png\n",
    "render_prompt(rand_img,rand_prompt,train_dataset,predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_max_iou_masks' from 'fine_tune.common' (/home/andrewhealey/sam-fine-tuning/fine_tune/common.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/andrewhealey/sam-fine-tuning/ft-train-new.test.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bandrew-dev.us-central1-a.roboflow-research/home/andrewhealey/sam-fine-tuning/ft-train-new.test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bandrew-dev.us-central1-a.roboflow-research/home/andrewhealey/sam-fine-tuning/ft-train-new.test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bandrew-dev.us-central1-a.roboflow-research/home/andrewhealey/sam-fine-tuning/ft-train-new.test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfine_tune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m SamDataset,get_max_iou_masks,to\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bandrew-dev.us-central1-a.roboflow-research/home/andrewhealey/sam-fine-tuning/ft-train-new.test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfine_tune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mviz\u001b[39;00m \u001b[39mimport\u001b[39;00m mask_to_img,clip_together_imgs, show_confusion_matrix, render_prompt\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_max_iou_masks' from 'fine_tune.common' (/home/andrewhealey/sam-fine-tuning/fine_tune/common.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import threshold, normalize\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import permutation\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from fine_tune.common import SamDataset,get_max_iou_masks,to\n",
    "from fine_tune.viz import mask_to_img,clip_together_imgs, show_confusion_matrix, render_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def evaluate():\n",
    "    pred_classes = []\n",
    "    gt_classes = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_count = 0\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_count = 0\n",
    "    \n",
    "    sam.eval()\n",
    "\n",
    "    for batch in tqdm(valid_curr_dataset):\n",
    "\n",
    "        batch = to(batch,device)\n",
    "        prompt_input, gt_info, gt_cls_info, imgs,sizes, prompt = batch\n",
    "\n",
    "        use_cls = cfg.model.decoder.use_cls and gt_cls_info is not None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_output = encoder.get_decoder_input(imgs,prompt)\n",
    "\n",
    "            low_res_masks, iou_predictions, cls_low_res_masks,cls_iou_predictions = pred = decoder(**prompt_input,**encoder_output)\n",
    "\n",
    "            _,losses = decoder.loss(*pred, gt_info,gt_cls_info, sizes,prompt)\n",
    "\n",
    "            normal_loss = losses[\"loss\"]\n",
    "            running_loss += normal_loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "            cls_loss = losses[\"cls_loss\"]\n",
    "            running_cls_loss += cls_loss.item()\n",
    "            running_cls_count += 1\n",
    "\n",
    "            if use_cls:\n",
    "                # get pred gt class\n",
    "                (cls_upscaled_masks,cls_binary_masks), pred_cls = decoder.postprocess(cls_low_res_masks,cls_iou_predictions,sizes)\n",
    "\n",
    "                _,_,_,best_cls,_ = get_max_iou_masks(gt_info[\"masks\"],cls_binary_masks,gt_cls_info[\"gt_cls\"],torch.arange(cfg.data.num_classes).to(device))\n",
    "\n",
    "                pred_classes.append(pred_cls)\n",
    "                gt_classes.append(best_cls)\n",
    "\n",
    "    valid_loss = running_loss/running_count\n",
    "    valid_cls_loss = running_cls_loss/running_cls_count\n",
    "\n",
    "    print(f\"VALID - Base loss: {valid_loss:.4f} - Class loss: {valid_cls_loss:.4f}\")\n",
    "\n",
    "    wandb.log({\n",
    "        \"valid_normal_loss\": valid_loss,\n",
    "        \"valid_cls_loss\": valid_cls_loss,\n",
    "    })\n",
    "\n",
    "    if len(gt_classes) > 0:\n",
    "        # calculate confusion matrix\n",
    "        show_confusion_matrix(gt_classes, pred_classes, class_names=valid_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from fine_tune.optimizer import get_optimizer\n",
    "\n",
    "optimizer,scheduler = get_optimizer(cfg,sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"sam-fine-tune\",\n",
    "    config=asdict(cfg)\n",
    ")\n",
    "\n",
    "curr_iters = 0\n",
    "accumulated_loss = 0\n",
    "\n",
    "# track running avg of loss\n",
    "recent_losses = []\n",
    "\n",
    "curr_epoch = 0\n",
    "\n",
    "# iter through dataset in random order\n",
    "while curr_iters < cfg.train.max_steps:\n",
    "    evaluate()\n",
    "    sam.train()\n",
    "    for i,idx in enumerate(tqdm(permutation(len(curr_dataset)))):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prompt_input, gt_info,gt_cls_info, imgs,sizes, prompt = batch = to(curr_dataset[idx],device)\n",
    "        \n",
    "        use_cls_loss = gt_cls_info is not None and cfg.model.decoder.use_cls\n",
    "        \n",
    "        has_fresh_prompt = True\n",
    "        refinements_remaining = cfg.train.num_refinement_steps\n",
    "\n",
    "        while has_fresh_prompt:\n",
    "            has_fresh_prompt = False\n",
    "\n",
    "            encoder_output = encoder.get_decoder_input(imgs,prompt)\n",
    "            low_res_masks, iou_predictions, cls_low_res_masks,cls_iou_predictions = pred = decoder(**prompt_input,**encoder_output)\n",
    "\n",
    "\n",
    "            #\n",
    "            # WandB\n",
    "            #\n",
    "            \n",
    "            loss,loss_dict = decoder.loss(*pred, gt_info,gt_cls_info, sizes,prompt)\n",
    "\n",
    "            input_img_torch = imgs[2]\n",
    "            image_embeddings= encoder_output[\"image_embeddings\"]\n",
    "\n",
    "            loss_dict = {k:v.item() for k,v in loss_dict.items()}\n",
    "            wandb.log(loss_dict)\n",
    "\n",
    "            #\n",
    "            # Logging\n",
    "            #\n",
    "\n",
    "            recent_losses += [loss.item()]\n",
    "            recent_losses = recent_losses[-cfg.train.log_period:]\n",
    "\n",
    "            if curr_iters % cfg.train.eval_period == 0:\n",
    "                evaluate()\n",
    "                sam.train()\n",
    "\n",
    "            if curr_iters % cfg.train.log_period == 0:\n",
    "                print(f\"Loss: {sum(recent_losses)/len(recent_losses)}\")\n",
    "\n",
    "            curr_iters += 1\n",
    "\n",
    "            if not cfg.train.run_grad: continue\n",
    "\n",
    "            accumulated_loss += loss\n",
    "            if curr_iters % cfg.train.batch_size == 0:\n",
    "                optimizer.zero_grad()\n",
    "                accumulated_loss /= torch.tensor(cfg.train.batch_size,dtype=torch.float32)\n",
    "                accumulated_loss.backward()\n",
    "                optimizer.step()\n",
    "                accumulated_loss = 0\n",
    "            \n",
    "            scheduler.step()\n",
    "\n",
    "            #\n",
    "            # Progressive refinement\n",
    "            #\n",
    "\n",
    "            if refinements_remaining > 0:\n",
    "\n",
    "                raise NotImplementedError(\"Need to update this to use new training system\")\n",
    "\n",
    "                refinements_remaining -= 1\n",
    "\n",
    "                has_fresh_prompt = True\n",
    "\n",
    "    curr_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "sam.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "runs_dir = \"runs_new\"\n",
    "run_ids = [int(fname) for fname in os.listdir(runs_dir)]\n",
    "highest_run = max(run_ids) if len(run_ids) > 0 else 0\n",
    "run_num = highest_run + 1\n",
    "export_dir = f\"{runs_dir}/{run_num}\"\n",
    "!mkdir -p $export_dir\n",
    "print(f\"Run saved to {export_dir}\")\n",
    "\n",
    "from fine_tune.export import export\n",
    "\n",
    "export(export_dir,cfg,sam,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "v_c_ds = valid_curr_dataset\n",
    "idx = randint(0,len(v_c_ds)-1)\n",
    "\n",
    "prompt_input, gt_info,gt_cls_info, imgs,sizes, prompt = batch = to(v_c_ds[idx],device)\n",
    "\n",
    "gt_masks = gt_info[\"masks\"]\n",
    "gt_cls = gt_cls_info[\"gt_cls\"]\n",
    "\n",
    "use_normal_tokens = True\n",
    "use_cls_tokens = cfg.model.decoder.use_cls and gt_cls_info is not None\n",
    "\n",
    "has_fresh_prompt = True\n",
    "num_refinements_left = cfg.train.num_refinement_steps\n",
    "while has_fresh_prompt:\n",
    "    has_fresh_prompt = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_output = encoder.get_decoder_input(imgs,prompt)\n",
    "        low_res_masks, iou_predictions, cls_low_res_masks,cls_iou_predictions = pred = decoder(**prompt_input,**encoder_output)\n",
    "\n",
    "        loss,losses = decoder.loss(*pred, gt_info,gt_cls_info, sizes,prompt)\n",
    "        \n",
    "        (upscaled_masks,binary_masks),max_idx = decoder.postprocess(low_res_masks,iou_predictions,sizes)\n",
    "        pred_iou = F.sigmoid(iou_predictions[0,max_idx]).item()\n",
    "        binary_mask = binary_masks[max_idx]\n",
    "\n",
    "        gt_binary_mask, _, _, _, _ = get_max_iou_masks(gt_masks,binary_mask[None,...])\n",
    "\n",
    "        if use_cls_tokens:\n",
    "\n",
    "            (cls_upscaled_masks,cls_binary_masks), pred_cls = decoder.postprocess(cls_low_res_masks,cls_iou_predictions,sizes)\n",
    "            cls_binary_mask = cls_binary_masks[pred_cls,...]\n",
    "\n",
    "            # get focal and dice loss between cls_binary_mask and closest gt mask\n",
    "            cls_gt_binary_mask,_,max_iou,best_cls,_ = get_max_iou_masks(gt_masks,cls_binary_masks,gt_cls,torch.arange(cfg.data.num_classes).to(device))\n",
    "\n",
    "        if num_refinements_left > 0:\n",
    "            raise NotImplementedError(\"Need to update this to use new training system\")\n",
    "\n",
    "            has_fresh_prompt = True\n",
    "            num_refinements_left -= 1\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "img = imgs[0]\n",
    "\n",
    "if use_normal_tokens:\n",
    "    print(\"Loss:\",losses[\"loss\"].item())\n",
    "    print(\"Predicted IoU:\",pred_iou,\"real IoU:\",max_iou.item())\n",
    "\n",
    "    clip_together_imgs(mask_to_img(binary_mask,img),mask_to_img(gt_binary_mask,img)).show()\n",
    "\n",
    "# print cls loss\n",
    "if use_cls_tokens:\n",
    "    print(\"Cls loss:\",losses[\"cls_loss\"].item())\n",
    "    print(\"Predicted cls:\",pred_cls.item(),\"GT cls:\",gt_cls.item())\n",
    "    print(\"Predicted cls IoU:\",pred_iou,\"real cls IoU:\",max_iou.item())\n",
    "\n",
    "    clip_together_imgs(mask_to_img(cls_binary_mask,img),mask_to_img(gt_binary_mask,img)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/andrewhealey/micromamba/envs/sam2/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/andrewhealey/micromamba/envs/sam2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "import fine_tune.viz\n",
    "\n",
    "name,prompt = choice(curr_dataset.prompts)\n",
    "render_prompt(name,prompt,train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
